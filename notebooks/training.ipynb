{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heart Disease Prediction - Model Training & Evaluation\n",
        "\n",
        "This notebook implements the complete machine learning pipeline for heart disease prediction, following the plan structure:\n",
        "\n",
        "## Table of Contents\n",
        "1. Setup & Data Loading\n",
        "2. Data Preprocessing \n",
        "3. Model Training (Logistic Regression & Random Forest)\n",
        "4. Hyperparameter Tuning\n",
        "5. Model Evaluation & Comparison\n",
        "6. Model Persistence\n",
        "7. Demo Predictions\n",
        "\n",
        "**Goal**: Build accurate models to predict heart disease risk and save the best performing model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Setup - Import libraries and configure environment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, ConfusionMatrixDisplay, \n",
        "                             RocCurveDisplay, classification_report)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "# Local utilities\n",
        "from utils import load_and_create_target, plot_confusion_matrix, plot_roc_curve, print_model_metrics\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìä Pandas: {pd.__version__}\")\n",
        "print(f\"üî¢ NumPy: {np.__version__}\")\n",
        "print(f\"ü§ñ Scikit-learn imported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Load data with target creation\n",
        "print(\"üìÇ Loading heart disease dataset...\")\n",
        "df = load_and_create_target('../data/heart_dataset.csv')\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìä Shape: {df.shape}\")\n",
        "print(f\"üéØ Target distribution: {df['target'].value_counts().to_dict()}\")\n",
        "\n",
        "# Separate features and target\n",
        "y = df['target'].astype(int)\n",
        "X = df.drop(columns=['target'])\n",
        "\n",
        "print(f\"\\nüìã Features: {list(X.columns)}\")\n",
        "print(f\"üî¢ Feature count: {X.shape[1]}\")\n",
        "print(f\"üìà Sample count: {X.shape[0]}\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nüìù First few samples:\")\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Basic data cleaning and feature identification\n",
        "print(\"üßπ Data preprocessing...\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = X.isnull().sum().sum()\n",
        "print(f\"‚ùì Missing values: {missing_values}\")\n",
        "\n",
        "# Identify feature types\n",
        "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "print(f\"üî¢ Numeric features ({len(num_cols)}): {num_cols}\")\n",
        "print(f\"üìã Categorical features ({len(cat_cols)}): {cat_cols}\")\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', 'passthrough', cat_cols)  # Keep categorical as-is since they're already encoded\n",
        "], remainder='drop')\n",
        "\n",
        "print(\"‚úÖ Preprocessor created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Train-test split\n",
        "print(\"‚úÇÔ∏è Splitting data into train and test sets...\")\n",
        "\n",
        "# Check if we have enough data for proper split\n",
        "if len(X) > 4:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, \n",
        "        stratify=y if len(np.unique(y)) > 1 else None\n",
        "    )\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: Very small dataset. Using all data for both training and testing.\")\n",
        "    X_train, X_test = X, X\n",
        "    y_train, y_test = y, y\n",
        "\n",
        "print(f\"üìä Training set: {X_train.shape}\")\n",
        "print(f\"üìä Test set: {X_test.shape}\")\n",
        "print(f\"üéØ Training target distribution: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"üéØ Test target distribution: {y_test.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Baseline Models Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) Define and train baseline models\n",
        "print(\"ü§ñ Training baseline models...\")\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"logistic_regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"random_forest\": RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "# Train each model\n",
        "for name, clf in models.items():\n",
        "    print(f\"\\nüîÑ Training {name.upper()}...\")\n",
        "    \n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([\n",
        "        ('preprocessor', preprocessor), \n",
        "        ('classifier', clf)\n",
        "    ])\n",
        "    \n",
        "    # Train model\n",
        "    pipe.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe['classifier'], \"predict_proba\") else None\n",
        "    \n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    }\n",
        "    \n",
        "    # Store results\n",
        "    results[name] = metrics\n",
        "    trained_models[name] = pipe\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"‚úÖ {name.upper()} Results:\")\n",
        "    print(f\"   Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"   Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"   F1 Score: {metrics['f1']:.4f}\")\n",
        "    if metrics['roc_auc']:\n",
        "        print(f\"   ROC AUC: {metrics['roc_auc']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üèÜ BASELINE MODELS TRAINING COMPLETE!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
