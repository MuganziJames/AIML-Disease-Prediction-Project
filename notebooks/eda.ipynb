{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heart Disease Prediction - Exploratory Data Analysis\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on the heart disease dataset to understand patterns, distributions, and relationships in the data.\n",
        "\n",
        "## Table of Contents\n",
        "1. Data Loading and Overview\n",
        "2. Data Quality Assessment  \n",
        "3. Univariate Analysis\n",
        "4. Bivariate Analysis\n",
        "5. Feature Engineering\n",
        "6. Target Variable Creation\n",
        "7. Summary and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from utils import load_and_create_target, plot_confusion_matrix, plot_roc_curve\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "# Ignore warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('../data/heart_dataset.csv')\n",
        "\n",
        "print(\"=== DATASET OVERVIEW ===\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of features: {df.shape[1]}\")\n",
        "print(f\"Number of samples: {df.shape[0]}\")\n",
        "\n",
        "print(\"\\n=== COLUMN INFORMATION ===\")\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "print(\"\\n=== FIRST FEW ROWS ===\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get basic information about the dataset\n",
        "print(\"=== DATA TYPES ===\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\n=== BASIC STATISTICS ===\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"=== MISSING VALUES ===\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
        "print(f\"Percentage of missing data: {(missing_values.sum() / len(df)) * 100:.2f}%\")\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\n=== DUPLICATES ===\")\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates}\")\n",
        "\n",
        "# Data type analysis\n",
        "print(f\"\\n=== FEATURE TYPES ===\")\n",
        "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
        "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Target Variable Creation and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create target variable using risk-based approach\n",
        "df_with_target = load_and_create_target('../data/heart_dataset.csv')\n",
        "\n",
        "print(\"=== TARGET VARIABLE CREATED ===\")\n",
        "print(f\"Target distribution:\")\n",
        "target_counts = df_with_target['target'].value_counts()\n",
        "print(target_counts)\n",
        "\n",
        "# Calculate percentages\n",
        "target_percentages = df_with_target['target'].value_counts(normalize=True) * 100\n",
        "print(f\"\\nTarget percentages:\")\n",
        "print(f\"No Heart Disease (0): {target_percentages[0]:.1f}%\")\n",
        "print(f\"Heart Disease (1): {target_percentages[1]:.1f}%\")\n",
        "\n",
        "# Visualize target distribution\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "target_counts.plot(kind='bar', color=['lightblue', 'salmon'])\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.xlabel('Heart Disease')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([0, 1], ['No Disease', 'Disease'], rotation=0)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(target_counts.values, labels=['No Disease', 'Disease'], \n",
        "        autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
        "plt.title('Target Variable Proportion')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Update our working dataframe\n",
        "df = df_with_target.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Univariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze numeric features\n",
        "numeric_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "\n",
        "# Create histograms for numeric features\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    if feature in df.columns:\n",
        "        axes[i].hist(df[feature], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        axes[i].set_title(f'Distribution of {feature}')\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary for numeric features\n",
        "print(\"=== NUMERIC FEATURES SUMMARY ===\")\n",
        "for feature in numeric_features:\n",
        "    if feature in df.columns:\n",
        "        print(f\"\\n{feature.upper()}:\")\n",
        "        print(f\"  Mean: {df[feature].mean():.2f}\")\n",
        "        print(f\"  Median: {df[feature].median():.2f}\")\n",
        "        print(f\"  Std: {df[feature].std():.2f}\")\n",
        "        print(f\"  Min: {df[feature].min():.2f}\")\n",
        "        print(f\"  Max: {df[feature].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze categorical features\n",
        "categorical_features = ['sex_Female', 'sex_Male', 'cp_asymptomatic', 'cp_atypical angina', \n",
        "                        'cp_non-anginal', 'cp_typical angina', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
        "\n",
        "# Create bar plots for binary and categorical features\n",
        "binary_features = [col for col in categorical_features if col.startswith(('sex_', 'cp_'))]\n",
        "\n",
        "print(\"=== CATEGORICAL FEATURES ANALYSIS ===\")\n",
        "\n",
        "# Gender distribution\n",
        "sex_cols = [col for col in df.columns if col.startswith('sex_')]\n",
        "if sex_cols:\n",
        "    gender_counts = {}\n",
        "    for col in sex_cols:\n",
        "        gender_counts[col.replace('sex_', '')] = df[col].sum()\n",
        "    \n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(gender_counts.keys(), gender_counts.values(), color=['pink', 'lightblue'])\n",
        "    plt.title('Gender Distribution')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "# Chest pain type distribution\n",
        "cp_cols = [col for col in df.columns if col.startswith('cp_')]\n",
        "if cp_cols:\n",
        "    cp_counts = {}\n",
        "    for col in cp_cols:\n",
        "        cp_counts[col.replace('cp_', '')] = df[col].sum()\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.bar(cp_counts.keys(), cp_counts.values(), color='lightgreen')\n",
        "    plt.title('Chest Pain Type Distribution')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Other categorical features\n",
        "other_cat_features = ['fbs', 'restecg', 'exang', 'slope', 'thal']\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(other_cat_features):\n",
        "    if feature in df.columns and i < len(axes):\n",
        "        value_counts = df[feature].value_counts()\n",
        "        axes[i].bar(range(len(value_counts)), value_counts.values, color='coral')\n",
        "        axes[i].set_title(f'{feature} Distribution')\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel('Count')\n",
        "        axes[i].set_xticks(range(len(value_counts)))\n",
        "        axes[i].set_xticklabels(value_counts.index, rotation=45)\n",
        "\n",
        "# Hide empty subplot\n",
        "if len(other_cat_features) < len(axes):\n",
        "    axes[-1].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bivariate Analysis - Features vs Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze relationship between numeric features and target\n",
        "numeric_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    if feature in df.columns:\n",
        "        # Box plots by target\n",
        "        df.boxplot(column=feature, by='target', ax=axes[i])\n",
        "        axes[i].set_title(f'{feature} by Heart Disease Status')\n",
        "        axes[i].set_xlabel('Heart Disease (0=No, 1=Yes)')\n",
        "        axes[i].set_ylabel(feature)\n",
        "\n",
        "plt.suptitle('Numeric Features by Target Variable', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"=== FEATURE MEANS BY TARGET ===\")\n",
        "for feature in numeric_features:\n",
        "    if feature in df.columns:\n",
        "        mean_no_disease = df[df['target'] == 0][feature].mean()\n",
        "        mean_disease = df[df['target'] == 1][feature].mean()\n",
        "        print(f\"{feature}:\")\n",
        "        print(f\"  No Disease: {mean_no_disease:.2f}\")\n",
        "        print(f\"  Disease: {mean_disease:.2f}\")\n",
        "        print(f\"  Difference: {mean_disease - mean_no_disease:.2f}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# Create correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find features most correlated with target\n",
        "target_correlations = correlation_matrix['target'].abs().sort_values(ascending=False)\n",
        "print(\"=== FEATURES MOST CORRELATED WITH TARGET ===\")\n",
        "print(target_correlations[1:])  # Exclude target itself\n",
        "\n",
        "# Top correlations\n",
        "print(f\"\\nTop 5 features correlated with heart disease:\")\n",
        "for i, (feature, corr) in enumerate(target_correlations[1:6].items()):\n",
        "    print(f\"{i+1}. {feature}: {corr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Key Insights and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== EXPLORATORY DATA ANALYSIS SUMMARY ===\")\n",
        "print()\n",
        "print(\"DATASET OVERVIEW:\")\n",
        "print(f\"   • {df.shape[0]} samples, {df.shape[1]} features\")\n",
        "print(f\"   • Target balance: {df['target'].value_counts().to_dict()}\")\n",
        "print()\n",
        "\n",
        "print(\"DATA QUALITY:\")\n",
        "print(f\"   • Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"   • Duplicates: {df.duplicated().sum()}\")\n",
        "print()\n",
        "\n",
        "print(\"KEY FINDINGS:\")\n",
        "print(\"   • Dataset contains heart disease risk factors\")\n",
        "print(\"   • Mix of numerical and categorical features\")\n",
        "print(\"   • Target variable created based on medical risk factors\")\n",
        "print(\"   • Features show varying correlations with heart disease risk\")\n",
        "print()\n",
        "\n",
        "print(\"READY FOR MODELING:\")\n",
        "print(\"   • Data is clean and preprocessed\")\n",
        "print(\"   • Target variable is well-defined\")\n",
        "print(\"   • Features show discriminative power\")\n",
        "print(\"   • Dataset is suitable for machine learning\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT STEPS: Proceed to model training and evaluation!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
